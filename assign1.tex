\section{Assignment 1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{} %1.1

Since
\begin{align}
    P(Y_i=0) &= P(X_i\le\mu) = F_X(\mu), \\
    P(Y_i=1) &= 1 - F_X(\mu).
\end{align}
We know $Y_i\sim Bernoulli(1-F_X(\mu))$ and are iid.
So the sum is a Binomial distribution. \ie
\begin{equation}
    \sum_{i=1}^n Y_i = Binomial(n, 1 - F_X(\mu)).
\end{equation}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{} %1.2

If we model the Binomial distribution as counting heads of tossing a biased coin,
then the sum of independent Binomial distributions is just tossing more times.
So the result should be another Binomial distribution.
\ie, $\sum_{i=1}^{k}X_i \sim Binomial\big(\sum_i n_i, p\big)$.

Formally, we only need to prove for the case of $k=2$.
\begin{align}
    P(X_1+X_2=t) &= \sum_{i=0}^t P(X_1=i)P(X_2=t-i) \\
                 &= \sum_{i=0}^t \binom{n_1}{i}p^{i}(1-p)^{n_1-i}\binom{n_2}{t-i}p^{t-i}(1-p)^{n_2-(t-i)} \\
                 &= p^{t}(1-p)^{n_1+n_2-t}\sum_{i=0}^t \binom{n_1}{i}\binom{n_2}{t-i} \\
                 &= \binom{n_1+n_2}{t}p^{t}(1-p)^{n_1+n_2-t}
\end{align}
So $X_1+X_2\sim Binomial(n_1+n_2, p)$.
Simple induction will suffice for proving the general case for $k>2$.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{} %1.3

\subsubsection{} %1.3.1

We write the marginal distribution in terms of conditional distribution \wrt $p$.
\begin{align}
    P(X_1=x_1,\dots,X_k=x_k)
        &= \int_0^1 P(X_1=x_1,\dots,X_k=x_k|p=u) du
\end{align}
Under condition $p=u$, $X_i$'s are independent,
so the marginal is
\begin{equation}
    P(X_1=x_1,\dots,X_k=x_k|p=u) = u^t(1-u)^{k-t}.
\end{equation}
Together, we have the desired equation
\begin{equation} \label{eq:1_3_1}
    P(X_1=x_1,\dots,X_k=x_k) = \int_0^1 p^t(1-p)^{k-t}dp.
\end{equation}
RHS of Equation \eqref{eq:1_3_1} is invariant under permutation of $X_i$,
so $X_1,\dots,X_n$ are exchangeable.

\subsubsection{} %1.3.2

\begin{equation}
    P(X_i=x_i) = \int_0^1 p^{x_i}(1-p)^{1-x_i} dp
\end{equation}

Consider the case that $X_i=1, \forall i$.
\begin{align}
    P(X_1=1,\dots,X_n=1) &= \int_0^1 p^n dp = \frac{1}{n+1}, \\
    P(X_1=1)\cdots P(X_n=1) &= \int_0^1 p dp\; \dots  \int_0^1 p dp = \frac{1}{2^n}.
\end{align}
So they are not equal.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{} %1.4

\subsubsection{} %1.4.1

For $X\sim Binomial(n,p)$,
\begin{align}
    M_X(t)
        &= \Ebb[e^{tX}] \\
        &= \sum_{i=0}^n \binom{n}{i}p^i(1-p)^{n-i}e^{ti} \\
        &= (pe^t + (1-p))^n \\
        &= (1-p+pe^t)^n.
\end{align}

\subsubsection{} %1.4.2

For $X\sim Pois(\lambda)$,
\begin{align}
    M_X(t)
        &= \Ebb[e^{tX}] \\
        &= \sum_{i=0}^\infty \frac{\lambda^i}{i!}e^{-\lambda}e^{ti} \\
        &= e^{-\lambda}e^{\lambda e^t} \\
        &= e^{\lambda(e^t-1)}.
\end{align}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{} %1.5

Let the cdf of std normal be $F(z)$.
\begin{align}
    F_Z(z)
        &= P(Z\le z) \\
        &= P(X\le z) + P(Y\le z) - P(X\le z)P(Y\le z) \\
        &= 2F(z) - (F(z))^2.
\end{align}
For $u\ge0$, we have $F(-u)=1-F(u)$. Then
\begin{align}
    P(Z^2\le u^2)
        &= P(-u\le Z\le u) \\
        &= F_Z(u) - F_Z(-u) \\
        &= 2F(u) - (F(u))^2 - (2F(-u) - (F(-u))^2) \\
        &= 2F(u) - (F(u))^2 - (1 - 2F(u) - (1 - F(u))^2) \\
        &= 2F(u) - 1.
\end{align}
This shows that $Z^2\sim \chi_1^2$.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{} %1.6

\begin{align}
    E(c\sqrt{S^2})
        &= E\vast(c\sqrt{\frac{1}{n}\sum_{i=1}^n(X_i-\mu)^2}\vast) \\
        &= \frac{c\sigma}{\sqrt{n}}E\vast(\sqrt{\sum_{i=1}^n\bigg(\frac{X_i-\mu}{\sigma}\bigg)^2}\vast) \\
        &= \sigma
\end{align}
Let
\begin{equation}
    Y:=\sum_{i=1}^n\bigg(\frac{X_i-\mu}{\sigma}\bigg)^2.
\end{equation}
Then $Y\sim\chi^2_n$.
From \cite{chi}, the square root of a chi-squared distribution is a chi distribution.
And the expectation is
\begin{equation}
    E\big(\sqrt{Y}\big) = \frac{\sqrt{2}\Gamma(\frac{n+1}{2})}{\Gamma(\frac{n}{2})}.
\end{equation}
Then,
\begin{equation}
    c = \frac{\sqrt{n}}{E\big(\sqrt{Y}\big)}
      = \frac{\sqrt{n}\Gamma(\frac{n}{2})}{\sqrt{2}\Gamma(\frac{n+1}{2})}.
\end{equation}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{} %1.7
