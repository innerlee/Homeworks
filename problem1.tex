\section{Problem 1}~\label{sec:prob1}

\subsection{} % 1.1

Under the conditions specified in the problem,
we cannot arrive at that conclusion.
Here is an counter example.
Let $m=n=r$, then $U=V=\real^n$.
So $\M=\Mbar=\real^{n\times n}$.

To make this question more sensible,
let us impose an extra condition that
$r<\min(m,n)=m$.
First the fact that $\M \subset \Mbar$ is trivial to verify
($\forall X \in \M$ and $\forall Y \in \Mbar^\perp$, $X\cdot Y=0$,
so $\M \subset (\Mbar^\perp)^\perp=\Mbar$).
We focus on why it is a proper subset.

Construct two orthogonal matrices $P\in\real^{m\times r}$,
and $Q\in \real^{r\times n}$, s.t.,
$\col(P)=U$ and $\row(Q)=V$.
Then $\forall X\in\M$, it can be decomposed as
$X=P\Sigma Q$, where $\Sigma\in\real^{r\times r}$
(This is fairly easy to see after an svd on X).
The decomposition is unique.
For two decompositions of $X$,
say $X=P\Sigma_1 Q=P\Sigma_2 Q$,
then multiply $P^T$ and $Q^T$ at the left and right hand of the equation,
we have $\Sigma_1=\Sigma_2$.
So we get an one-to-one mapping from $\M$ to $\real^{r\times r}$.
This mapping is also linear (easy to verify).
Thus $\dim \M \le \dim \real^{r\times r} = r^2$.
Similar story goes to $\Mbar^\perp$ and we have
$\dim \Mbar^\perp \le \dim \real^{(m-r)\times(m-r)} = (m-r)^2$.
Thus $\dim \M + \dim \Mbar^\perp \le r^2 + (m-r)^2 < m^2 \le mn = \dim \real^{m\times n}$.
This is a contradiction if $\M=\Mbar$ because
the sum of $\dim \Mbar(=\dim \M)$ and $\dim \Mbar^\perp$ should be $mn$ then.

\subsection{} % 1.2

Let orthogonal matrices $P=(P_1\ P_2)\in\real^{m\times m}$ and
$Q=(Q_1^T\ Q_2^T)^T\in\real^{n\times n}$, s.t.
$\col(P_1)=U, \col(P_1) = U^\perp, \row(Q_1) = V, \row(Q_2)=V^\perp$.
Then similar to the last sub-question,
$\forall X\in\M, \forall Y\in\Mbar^\perp$,
we can decompose them as
\begin{equation}
    X =
        \begin{bmatrix}
        P_1 & 0\\
        \end{bmatrix}
        \begin{bmatrix}
        \Sigma_1 &   0 \\
        0 & 0\\
        \end{bmatrix}
        \begin{bmatrix}
        Q_1 \\
        0 \\
        \end{bmatrix},\quad
        Y =
        \begin{bmatrix}
        0 & P_2\\
        \end{bmatrix}
        \begin{bmatrix}
        0 &   0 \\
        0 & \Sigma_2\\
        \end{bmatrix}
        \begin{bmatrix}
        0 \\
        Q_2 \\
        \end{bmatrix},
\end{equation}
where $\Sigma_1\in\real^{r\times r}$ and $\Sigma_2\in\real^{(m-r)\times(n-r)}$.
So,
\begin{equation}
    X + Y =
        \begin{bmatrix}
        P_1 & P_2\\
        \end{bmatrix}
        \begin{bmatrix}
        \Sigma_1 &   0 \\
        0 & \Sigma_2\\
        \end{bmatrix}
        \begin{bmatrix}
        Q_1 \\
        Q_2 \\
        \end{bmatrix}.
\end{equation}
Thus,
$\|X+Y\|_*=\|\Sigma_1+\Sigma_2\|_*=\|\Sigma_1\|_*+\|\Sigma_2\|_*=\|X\|_*+\|Y\|_*$.
