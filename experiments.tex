\section{Experiments and Visualization} \label{sec:exp}

To answer the questions raised in previous section,
we specially designed toy problems in low-dimensions,
so that we can visualize what happens in the training dynamics of GAN.
We use \emph{fully connected} layers as the building blocks for both
the generator and discriminator.
After each fully connected layer,
we add a \emph{batch normalization} layer and a \emph{Elu} activation layer.
Both the latent space and the data space is
restricted to $1$-dimension or $2$-dimension.
Across all experiments,
we use fc networks with
$20-40-100-200-200-100-40-20$ hidden neuron numbers
as the structure for generator.
The same hidden neuron setting is also applied to the discriminator.
The capacity of these networks is large enough for our experiments.

We use \emph{Parrots}~\cite{parrots} as the deep learning framework
and use the the Julia port \emph{Parrots.jl}~\cite{parrotsjl}
as the working language.
All codes were implemented from scratch based on
the algorithm described in~\cite{goodfellow2014generative}.
Codes and experiment results are available at
\url{https://github.com/innerlee/ELEG5491}.

\subsection{Dimensionality}

\subsection{Connectivity}

\subsection{Topology}
